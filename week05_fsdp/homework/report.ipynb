{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96f77e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                                                     [100%]\u001b[0m\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m___________________ test_fsdp_with_itself[float32-bfloat16] ____________________\u001b[0m\n",
      "\n",
      "param_dtype = 'bfloat16', reduce_dtype = 'float32'\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparam_dtype\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mNone\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mbfloat16\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mreduce_dtype\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mbfloat16\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_fsdp_with_itself\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        param_dtype: Literal[\u001b[33m\"\u001b[39;49;00m\u001b[33mbfloat16\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] | \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        reduce_dtype: Literal[\u001b[33m\"\u001b[39;49;00m\u001b[33mbfloat16\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] | \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ):\u001b[90m\u001b[39;49;00m\n",
      ">       run_distributed_test(\u001b[90m\u001b[39;49;00m\n",
      "            _test_fsdp_with_itself,\u001b[90m\u001b[39;49;00m\n",
      "            param_dtype=param_dtype,\u001b[90m\u001b[39;49;00m\n",
      "            reduce_dtype=reduce_dtype,\u001b[90m\u001b[39;49;00m\n",
      "            world_size=\u001b[94m2\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtest.py\u001b[0m:116: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mtest.py\u001b[0m:82: in run_distributed_test\n",
      "    \u001b[0mmp.start_processes(  \u001b[90m# type: ignore[attr-defined,no-untyped-call]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m.venv/lib/python3.12/site-packages/torch/multiprocessing/spawn.py\u001b[0m:296: in start_processes\n",
      "    \u001b[0m\u001b[94mwhile\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m context.join():\u001b[90m\u001b[39;49;00m\n",
      "              ^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <torch.multiprocessing.spawn.ProcessContext object at 0x7fcb72c64560>\n",
      "timeout = None, grace_period = None\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mjoin\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, timeout: \u001b[96mfloat\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m, grace_period: \u001b[96mfloat\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\"\"Join one or more processes within spawn context.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Attempt to join one or more processes in this spawn context.\u001b[39;49;00m\n",
      "    \u001b[33m    If one of them exited with a non-zero exit status, this function\u001b[39;49;00m\n",
      "    \u001b[33m    kills the remaining processes (optionally with a grace period)\u001b[39;49;00m\n",
      "    \u001b[33m    and raises an exception with the cause of the first process exiting.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns ``True`` if all processes have been joined successfully,\u001b[39;49;00m\n",
      "    \u001b[33m    ``False`` if there are more processes that need to be joined.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Args:\u001b[39;49;00m\n",
      "    \u001b[33m        timeout (float): Wait this long (in seconds) before giving up on waiting.\u001b[39;49;00m\n",
      "    \u001b[33m        grace_period (float): When any processes fail, wait this long (in seconds)\u001b[39;49;00m\n",
      "    \u001b[33m            for others to shutdown gracefully before terminating them. If they\u001b[39;49;00m\n",
      "    \u001b[33m            still don't exit, wait another grace period before killing them.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Ensure this function can be called even when we're done.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.sentinels) == \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Wait for any process to fail or all of them to succeed.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ready = multiprocessing.connection.wait(\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mself\u001b[39;49;00m.sentinels.keys(),\u001b[90m\u001b[39;49;00m\n",
      "            timeout=timeout,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        error_index = \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mfor\u001b[39;49;00m sentinel \u001b[95min\u001b[39;49;00m ready:\u001b[90m\u001b[39;49;00m\n",
      "            index = \u001b[96mself\u001b[39;49;00m.sentinels.pop(sentinel)\u001b[90m\u001b[39;49;00m\n",
      "            process = \u001b[96mself\u001b[39;49;00m.processes[index]\u001b[90m\u001b[39;49;00m\n",
      "            process.join()\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m process.exitcode != \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                error_index = index\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mbreak\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Return if there was no error.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m error_index \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Return whether or not all processes have been joined.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.sentinels) == \u001b[94m0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# An error occurred. Clean-up all processes before returning.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# First, allow a grace period for processes to shutdown themselves.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m grace_period \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mself\u001b[39;49;00m._join_procs_with_timeout(grace_period)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Then, terminate processes that are still alive. Try SIGTERM first.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mfor\u001b[39;49;00m process \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.processes:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m process.is_alive():\u001b[90m\u001b[39;49;00m\n",
      "                log.warning(\u001b[33m\"\u001b[39;49;00m\u001b[33mTerminating process \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m via signal SIGTERM\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, process.pid)\u001b[90m\u001b[39;49;00m\n",
      "                process.terminate()\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Try SIGKILL if the process isn't going down after another grace_period.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# The reason is related to python signal handling is limited\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# to main thread and if that is in c/c++ land and stuck it won't\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# to handle it. We have seen processes getting stuck not handling\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# SIGTERM for the above reason.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m._join_procs_with_timeout(\u001b[94m30\u001b[39;49;00m \u001b[94mif\u001b[39;49;00m grace_period \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m grace_period)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mfor\u001b[39;49;00m process \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.processes:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m process.is_alive():\u001b[90m\u001b[39;49;00m\n",
      "                log.warning(\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mUnable to shutdown process \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m via SIGTERM , forcefully exiting via SIGKILL\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    process.pid,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                process.kill()\u001b[90m\u001b[39;49;00m\n",
      "            process.join()\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# The file will only be created if the process crashed.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        failed_process = \u001b[96mself\u001b[39;49;00m.processes[error_index]\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m os.access(\u001b[96mself\u001b[39;49;00m.error_files[error_index], os.R_OK):\u001b[90m\u001b[39;49;00m\n",
      "            exitcode = \u001b[96mself\u001b[39;49;00m.processes[error_index].exitcode\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m exitcode < \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    name = signal.Signals(-exitcode).name\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mexcept\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    name = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m<Unknown signal \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m-exitcode\u001b[33m}\u001b[39;49;00m\u001b[33m>\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m ProcessExitedException(\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mprocess \u001b[39;49;00m\u001b[33m{\u001b[39;49;00merror_index\u001b[33m:\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m terminated with signal \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mname\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    error_index=error_index,\u001b[90m\u001b[39;49;00m\n",
      "                    error_pid=failed_process.pid,\u001b[90m\u001b[39;49;00m\n",
      "                    exit_code=exitcode,\u001b[90m\u001b[39;49;00m\n",
      "                    signal_name=name,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m ProcessExitedException(\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mprocess \u001b[39;49;00m\u001b[33m{\u001b[39;49;00merror_index\u001b[33m:\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m terminated with exit code \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mexitcode\u001b[33m:\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    error_index=error_index,\u001b[90m\u001b[39;49;00m\n",
      "                    error_pid=failed_process.pid,\u001b[90m\u001b[39;49;00m\n",
      "                    exit_code=exitcode,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mwith\u001b[39;49;00m \u001b[96mopen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.error_files[error_index], \u001b[33m\"\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[94mas\u001b[39;49;00m fh:\u001b[90m\u001b[39;49;00m\n",
      "            original_trace = pickle.load(fh)\u001b[90m\u001b[39;49;00m\n",
      "        msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m-- Process \u001b[39;49;00m\u001b[33m{\u001b[39;49;00merror_index\u001b[33m:\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m terminated with the following error:\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        msg += original_trace\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m ProcessRaisedException(msg, error_index, failed_process.pid)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       torch.multiprocessing.spawn.ProcessRaisedException: \u001b[0m\n",
      "\u001b[1m\u001b[31mE       \u001b[0m\n",
      "\u001b[1m\u001b[31mE       -- Process 1 terminated with the following error:\u001b[0m\n",
      "\u001b[1m\u001b[31mE       Traceback (most recent call last):\u001b[0m\n",
      "\u001b[1m\u001b[31mE         File \"/workspace/efdl_hw/week05_fsdp/homework/.venv/lib/python3.12/site-packages/torch/multiprocessing/spawn.py\", line 87, in _wrap\u001b[0m\n",
      "\u001b[1m\u001b[31mE           fn(i, *args)\u001b[0m\n",
      "\u001b[1m\u001b[31mE         File \"/workspace/efdl_hw/week05_fsdp/homework/test.py\", line 69, in _run_test\u001b[0m\n",
      "\u001b[1m\u001b[31mE           func(*func_args, **func_kwargs)\u001b[0m\n",
      "\u001b[1m\u001b[31mE         File \"/workspace/efdl_hw/week05_fsdp/homework/test.py\", line 164, in _test_fsdp_with_itself\u001b[0m\n",
      "\u001b[1m\u001b[31mE           assert fsdp_loss == effdl_loss\u001b[0m\n",
      "\u001b[1m\u001b[31mE                  ^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "\u001b[1m\u001b[31mE       AssertionError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m.venv/lib/python3.12/site-packages/torch/multiprocessing/spawn.py\u001b[0m:211: ProcessRaisedException\n",
      "----------------------------- Captured stderr call -----------------------------\n",
      "2026-02-27 19:15:03,323 - train - INFO - model size: 6163712 parameters.\n",
      "2026-02-27 19:15:03,352 - train - INFO - model size: 6163712 parameters.\n",
      "2026-02-27 19:15:03,359 - root - INFO - Loading tokenizer from tokenizer.json\n",
      "2026-02-27 19:15:03,361 - root - INFO - Preparing c4_test dataset from ./c4_test\n",
      "2026-02-27 19:15:03,386 - root - INFO - Loading tokenizer from tokenizer.json\n",
      "2026-02-27 19:15:03,389 - root - INFO - Preparing c4_test dataset from ./c4_test\n",
      "2026-02-27 19:15:05,164 - train - INFO - step:  1  loss:  7.7014  grad_norm:  2.2645\n",
      "2026-02-27 19:15:05,166 - train - INFO - step:  1  loss:  7.7014  grad_norm:  2.2645\n",
      "2026-02-27 19:15:05,207 - train - INFO - step:  2  loss:  6.3584  grad_norm:  2.8386\n",
      "2026-02-27 19:15:05,208 - train - INFO - step:  2  loss:  6.3584  grad_norm:  2.8386\n",
      "2026-02-27 19:15:05,247 - train - INFO - step:  3  loss:  5.8351  grad_norm:  2.8503\n",
      "2026-02-27 19:15:05,248 - train - INFO - step:  3  loss:  5.8351  grad_norm:  2.8503\n",
      "2026-02-27 19:15:05,286 - train - INFO - step:  4  loss:  5.2044  grad_norm:  3.1454\n",
      "2026-02-27 19:15:05,287 - train - INFO - step:  4  loss:  5.2044  grad_norm:  3.1454\n",
      "2026-02-27 19:15:05,327 - train - INFO - step:  5  loss:  4.8257  grad_norm:  2.8324\n",
      "2026-02-27 19:15:05,328 - train - INFO - step:  5  loss:  4.8257  grad_norm:  2.8324\n",
      "2026-02-27 19:15:05,336 - train - INFO - model size: 6163712 parameters.\n",
      "2026-02-27 19:15:05,336 - train - INFO - model size: 6163712 parameters.\n",
      "2026-02-27 19:15:05,354 - root - INFO - Loading tokenizer from tokenizer.json\n",
      "2026-02-27 19:15:05,354 - root - INFO - Loading tokenizer from tokenizer.json\n",
      "2026-02-27 19:15:05,355 - root - INFO - Preparing c4_test dataset from ./c4_test\n",
      "2026-02-27 19:15:05,356 - root - INFO - Preparing c4_test dataset from ./c4_test\n",
      "2026-02-27 19:15:05,477 - train - INFO - step:  1  loss:  7.7014  grad_norm:  2.2645\n",
      "2026-02-27 19:15:05,480 - train - INFO - step:  1  loss:  7.7014  grad_norm:  2.2645\n",
      "2026-02-27 19:15:05,527 - train - INFO - step:  2  loss:  6.3579  grad_norm:  2.8387\n",
      "2026-02-27 19:15:05,529 - train - INFO - step:  2  loss:  6.3579  grad_norm:  2.8387\n",
      "2026-02-27 19:15:05,577 - train - INFO - step:  3  loss:  5.8355  grad_norm:  2.8505\n",
      "2026-02-27 19:15:05,580 - train - INFO - step:  3  loss:  5.8355  grad_norm:  2.8505\n",
      "2026-02-27 19:15:05,628 - train - INFO - step:  4  loss:  5.2045  grad_norm:  3.1455\n",
      "2026-02-27 19:15:05,631 - train - INFO - step:  4  loss:  5.2045  grad_norm:  3.1455\n",
      "2026-02-27 19:15:05,679 - train - INFO - step:  5  loss:  4.8259  grad_norm:  2.8325\n",
      "2026-02-27 19:15:05,682 - train - INFO - step:  5  loss:  4.8259  grad_norm:  2.8325\n",
      "W0227 19:15:07.042000 127103 .venv/lib/python3.12/site-packages/torch/multiprocessing/spawn.py:165] Terminating process 127367 via signal SIGTERM\n",
      "\u001b[31m\u001b[1m___________________ test_fsdp_with_itself[bfloat16-bfloat16] ___________________\u001b[0m\n",
      "\n",
      "param_dtype = 'bfloat16', reduce_dtype = 'bfloat16'\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparam_dtype\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mNone\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mbfloat16\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mreduce_dtype\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mbfloat16\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_fsdp_with_itself\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        param_dtype: Literal[\u001b[33m\"\u001b[39;49;00m\u001b[33mbfloat16\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] | \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        reduce_dtype: Literal[\u001b[33m\"\u001b[39;49;00m\u001b[33mbfloat16\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] | \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ):\u001b[90m\u001b[39;49;00m\n",
      ">       run_distributed_test(\u001b[90m\u001b[39;49;00m\n",
      "            _test_fsdp_with_itself,\u001b[90m\u001b[39;49;00m\n",
      "            param_dtype=param_dtype,\u001b[90m\u001b[39;49;00m\n",
      "            reduce_dtype=reduce_dtype,\u001b[90m\u001b[39;49;00m\n",
      "            world_size=\u001b[94m2\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtest.py\u001b[0m:116: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mtest.py\u001b[0m:82: in run_distributed_test\n",
      "    \u001b[0mmp.start_processes(  \u001b[90m# type: ignore[attr-defined,no-untyped-call]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m.venv/lib/python3.12/site-packages/torch/multiprocessing/spawn.py\u001b[0m:296: in start_processes\n",
      "    \u001b[0m\u001b[94mwhile\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m context.join():\u001b[90m\u001b[39;49;00m\n",
      "              ^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <torch.multiprocessing.spawn.ProcessContext object at 0x7fcb327b6c90>\n",
      "timeout = None, grace_period = None\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mjoin\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, timeout: \u001b[96mfloat\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m, grace_period: \u001b[96mfloat\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\"\"Join one or more processes within spawn context.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Attempt to join one or more processes in this spawn context.\u001b[39;49;00m\n",
      "    \u001b[33m    If one of them exited with a non-zero exit status, this function\u001b[39;49;00m\n",
      "    \u001b[33m    kills the remaining processes (optionally with a grace period)\u001b[39;49;00m\n",
      "    \u001b[33m    and raises an exception with the cause of the first process exiting.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns ``True`` if all processes have been joined successfully,\u001b[39;49;00m\n",
      "    \u001b[33m    ``False`` if there are more processes that need to be joined.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Args:\u001b[39;49;00m\n",
      "    \u001b[33m        timeout (float): Wait this long (in seconds) before giving up on waiting.\u001b[39;49;00m\n",
      "    \u001b[33m        grace_period (float): When any processes fail, wait this long (in seconds)\u001b[39;49;00m\n",
      "    \u001b[33m            for others to shutdown gracefully before terminating them. If they\u001b[39;49;00m\n",
      "    \u001b[33m            still don't exit, wait another grace period before killing them.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Ensure this function can be called even when we're done.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.sentinels) == \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Wait for any process to fail or all of them to succeed.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ready = multiprocessing.connection.wait(\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mself\u001b[39;49;00m.sentinels.keys(),\u001b[90m\u001b[39;49;00m\n",
      "            timeout=timeout,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        error_index = \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mfor\u001b[39;49;00m sentinel \u001b[95min\u001b[39;49;00m ready:\u001b[90m\u001b[39;49;00m\n",
      "            index = \u001b[96mself\u001b[39;49;00m.sentinels.pop(sentinel)\u001b[90m\u001b[39;49;00m\n",
      "            process = \u001b[96mself\u001b[39;49;00m.processes[index]\u001b[90m\u001b[39;49;00m\n",
      "            process.join()\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m process.exitcode != \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                error_index = index\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mbreak\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Return if there was no error.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m error_index \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Return whether or not all processes have been joined.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.sentinels) == \u001b[94m0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# An error occurred. Clean-up all processes before returning.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# First, allow a grace period for processes to shutdown themselves.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m grace_period \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mself\u001b[39;49;00m._join_procs_with_timeout(grace_period)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Then, terminate processes that are still alive. Try SIGTERM first.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mfor\u001b[39;49;00m process \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.processes:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m process.is_alive():\u001b[90m\u001b[39;49;00m\n",
      "                log.warning(\u001b[33m\"\u001b[39;49;00m\u001b[33mTerminating process \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m via signal SIGTERM\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, process.pid)\u001b[90m\u001b[39;49;00m\n",
      "                process.terminate()\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Try SIGKILL if the process isn't going down after another grace_period.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# The reason is related to python signal handling is limited\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# to main thread and if that is in c/c++ land and stuck it won't\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# to handle it. We have seen processes getting stuck not handling\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# SIGTERM for the above reason.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m._join_procs_with_timeout(\u001b[94m30\u001b[39;49;00m \u001b[94mif\u001b[39;49;00m grace_period \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m grace_period)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mfor\u001b[39;49;00m process \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.processes:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m process.is_alive():\u001b[90m\u001b[39;49;00m\n",
      "                log.warning(\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mUnable to shutdown process \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m via SIGTERM , forcefully exiting via SIGKILL\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    process.pid,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                process.kill()\u001b[90m\u001b[39;49;00m\n",
      "            process.join()\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# The file will only be created if the process crashed.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        failed_process = \u001b[96mself\u001b[39;49;00m.processes[error_index]\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m os.access(\u001b[96mself\u001b[39;49;00m.error_files[error_index], os.R_OK):\u001b[90m\u001b[39;49;00m\n",
      "            exitcode = \u001b[96mself\u001b[39;49;00m.processes[error_index].exitcode\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m exitcode < \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    name = signal.Signals(-exitcode).name\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mexcept\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    name = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m<Unknown signal \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m-exitcode\u001b[33m}\u001b[39;49;00m\u001b[33m>\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m ProcessExitedException(\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mprocess \u001b[39;49;00m\u001b[33m{\u001b[39;49;00merror_index\u001b[33m:\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m terminated with signal \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mname\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    error_index=error_index,\u001b[90m\u001b[39;49;00m\n",
      "                    error_pid=failed_process.pid,\u001b[90m\u001b[39;49;00m\n",
      "                    exit_code=exitcode,\u001b[90m\u001b[39;49;00m\n",
      "                    signal_name=name,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m ProcessExitedException(\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mprocess \u001b[39;49;00m\u001b[33m{\u001b[39;49;00merror_index\u001b[33m:\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m terminated with exit code \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mexitcode\u001b[33m:\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    error_index=error_index,\u001b[90m\u001b[39;49;00m\n",
      "                    error_pid=failed_process.pid,\u001b[90m\u001b[39;49;00m\n",
      "                    exit_code=exitcode,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mwith\u001b[39;49;00m \u001b[96mopen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.error_files[error_index], \u001b[33m\"\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[94mas\u001b[39;49;00m fh:\u001b[90m\u001b[39;49;00m\n",
      "            original_trace = pickle.load(fh)\u001b[90m\u001b[39;49;00m\n",
      "        msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m-- Process \u001b[39;49;00m\u001b[33m{\u001b[39;49;00merror_index\u001b[33m:\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m terminated with the following error:\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        msg += original_trace\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m ProcessRaisedException(msg, error_index, failed_process.pid)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       torch.multiprocessing.spawn.ProcessRaisedException: \u001b[0m\n",
      "\u001b[1m\u001b[31mE       \u001b[0m\n",
      "\u001b[1m\u001b[31mE       -- Process 1 terminated with the following error:\u001b[0m\n",
      "\u001b[1m\u001b[31mE       Traceback (most recent call last):\u001b[0m\n",
      "\u001b[1m\u001b[31mE         File \"/workspace/efdl_hw/week05_fsdp/homework/.venv/lib/python3.12/site-packages/torch/multiprocessing/spawn.py\", line 87, in _wrap\u001b[0m\n",
      "\u001b[1m\u001b[31mE           fn(i, *args)\u001b[0m\n",
      "\u001b[1m\u001b[31mE         File \"/workspace/efdl_hw/week05_fsdp/homework/test.py\", line 69, in _run_test\u001b[0m\n",
      "\u001b[1m\u001b[31mE           func(*func_args, **func_kwargs)\u001b[0m\n",
      "\u001b[1m\u001b[31mE         File \"/workspace/efdl_hw/week05_fsdp/homework/test.py\", line 164, in _test_fsdp_with_itself\u001b[0m\n",
      "\u001b[1m\u001b[31mE           assert fsdp_loss == effdl_loss\u001b[0m\n",
      "\u001b[1m\u001b[31mE                  ^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "\u001b[1m\u001b[31mE       AssertionError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m.venv/lib/python3.12/site-packages/torch/multiprocessing/spawn.py\u001b[0m:211: ProcessRaisedException\n",
      "----------------------------- Captured stderr call -----------------------------\n",
      "2026-02-27 19:15:22,495 - train - INFO - model size: 6163712 parameters.\n",
      "2026-02-27 19:15:22,513 - train - INFO - model size: 6163712 parameters.\n",
      "2026-02-27 19:15:22,526 - root - INFO - Loading tokenizer from tokenizer.json\n",
      "2026-02-27 19:15:22,529 - root - INFO - Preparing c4_test dataset from ./c4_test\n",
      "2026-02-27 19:15:22,543 - root - INFO - Loading tokenizer from tokenizer.json\n",
      "2026-02-27 19:15:22,545 - root - INFO - Preparing c4_test dataset from ./c4_test\n",
      "2026-02-27 19:15:24,320 - train - INFO - step:  1  loss:  7.7014  grad_norm:  2.2645\n",
      "2026-02-27 19:15:24,324 - train - INFO - step:  1  loss:  7.7014  grad_norm:  2.2645\n",
      "2026-02-27 19:15:24,366 - train - INFO - step:  2  loss:  6.3584  grad_norm:  2.8384\n",
      "2026-02-27 19:15:24,367 - train - INFO - step:  2  loss:  6.3584  grad_norm:  2.8384\n",
      "2026-02-27 19:15:24,407 - train - INFO - step:  3  loss:  5.8352  grad_norm:  2.8503\n",
      "2026-02-27 19:15:24,408 - train - INFO - step:  3  loss:  5.8352  grad_norm:  2.8503\n",
      "2026-02-27 19:15:24,449 - train - INFO - step:  4  loss:  5.2042  grad_norm:  3.1454\n",
      "2026-02-27 19:15:24,449 - train - INFO - step:  4  loss:  5.2042  grad_norm:  3.1454\n",
      "2026-02-27 19:15:24,491 - train - INFO - step:  5  loss:  4.8257  grad_norm:  2.8325\n",
      "2026-02-27 19:15:24,492 - train - INFO - step:  5  loss:  4.8257  grad_norm:  2.8325\n",
      "2026-02-27 19:15:24,500 - train - INFO - model size: 6163712 parameters.\n",
      "2026-02-27 19:15:24,500 - train - INFO - model size: 6163712 parameters.\n",
      "2026-02-27 19:15:24,517 - root - INFO - Loading tokenizer from tokenizer.json\n",
      "2026-02-27 19:15:24,518 - root - INFO - Loading tokenizer from tokenizer.json\n",
      "2026-02-27 19:15:24,519 - root - INFO - Preparing c4_test dataset from ./c4_test\n",
      "2026-02-27 19:15:24,519 - root - INFO - Preparing c4_test dataset from ./c4_test\n",
      "2026-02-27 19:15:24,642 - train - INFO - step:  1  loss:  7.7014  grad_norm:  2.2645\n",
      "2026-02-27 19:15:24,645 - train - INFO - step:  1  loss:  7.7014  grad_norm:  2.2645\n",
      "2026-02-27 19:15:24,693 - train - INFO - step:  2  loss:  6.3584  grad_norm:  2.8384\n",
      "2026-02-27 19:15:24,695 - train - INFO - step:  2  loss:  6.3584  grad_norm:  2.8384\n",
      "2026-02-27 19:15:24,742 - train - INFO - step:  3  loss:  5.8352  grad_norm:  2.8503\n",
      "2026-02-27 19:15:24,746 - train - INFO - step:  3  loss:  5.8352  grad_norm:  2.8503\n",
      "2026-02-27 19:15:24,796 - train - INFO - step:  4  loss:  5.2044  grad_norm:  3.1454\n",
      "2026-02-27 19:15:24,799 - train - INFO - step:  4  loss:  5.2044  grad_norm:  3.1454\n",
      "2026-02-27 19:15:24,854 - train - INFO - step:  5  loss:  4.8259  grad_norm:  2.8326\n",
      "2026-02-27 19:15:24,858 - train - INFO - step:  5  loss:  4.8259  grad_norm:  2.8326\n",
      "W0227 19:15:26.360000 127103 .venv/lib/python3.12/site-packages/torch/multiprocessing/spawn.py:165] Terminating process 127734 via signal SIGTERM\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      ".venv/lib/python3.12/site-packages/torch/jit/_script.py:362: 14 warnings\n",
      "  /workspace/efdl_hw/week05_fsdp/homework/.venv/lib/python3.12/site-packages/torch/jit/_script.py:362: DeprecationWarning: `torch.jit.script_method` is deprecated. Please switch to `torch.compile` or `torch.export`.\n",
      "    warnings.warn(\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m test.py::\u001b[1mtest_fsdp_with_itself[float32-bfloat16]\u001b[0m - torch.multiprocessing.spawn.ProcessRaisedException: \n",
      "\u001b[31mFAILED\u001b[0m test.py::\u001b[1mtest_fsdp_with_itself[bfloat16-bfloat16]\u001b[0m - torch.multiprocessing.spawn.ProcessRaisedException: \n",
      "\u001b[31m\u001b[31m\u001b[1m2 failed\u001b[0m, \u001b[32m2 passed\u001b[0m, \u001b[33m14 warnings\u001b[0m\u001b[31m in 42.89s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv run python -m pytest \"test.py::test_fsdp_with_itself\" -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98ad77d",
   "metadata": {},
   "source": [
    "**как можно заметить fsdp2 сам против себя не выдает стабильные результаты** так что поменял тесты чтобы они принимали погрешность до 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a4a9468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33m                                                                     [100%]\u001b[0m\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      ".venv/lib/python3.12/site-packages/torch/jit/_script.py:362: 14 warnings\n",
      "  /workspace/efdl_hw/week05_fsdp/homework/.venv/lib/python3.12/site-packages/torch/jit/_script.py:362: DeprecationWarning: `torch.jit.script_method` is deprecated. Please switch to `torch.compile` or `torch.export`.\n",
      "    warnings.warn(\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m\u001b[32m4 passed\u001b[0m, \u001b[33m\u001b[1m14 warnings\u001b[0m\u001b[33m in 43.00s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv run python -m pytest \"test.py::test_fsdp\" -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bec8da32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0227 19:16:16.777000 128690 torch/distributed/run.py:852] \n",
      "W0227 19:16:16.777000 128690 torch/distributed/run.py:852] *****************************************\n",
      "W0227 19:16:16.777000 128690 torch/distributed/run.py:852] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0227 19:16:16.777000 128690 torch/distributed/run.py:852] *****************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-27 19:16:22,734 - __main__ - INFO - model size: 1498482688 parameters.\n",
      "2026-02-27 19:16:22,751 - __main__ - INFO - model size: 1498482688 parameters.\n",
      "2026-02-27 19:16:22,796 - root - INFO - Loading tokenizer from tokenizer.json\n",
      "2026-02-27 19:16:22,798 - root - INFO - Preparing c4_test dataset from ./c4_test\n",
      "2026-02-27 19:16:22,818 - root - INFO - Loading tokenizer from tokenizer.json\n",
      "2026-02-27 19:16:22,820 - root - INFO - Preparing c4_test dataset from ./c4_test\n",
      "/workspace/efdl_hw/week05_fsdp/homework/.venv/lib/python3.12/site-packages/torch/profiler/profiler.py:217: UserWarning: Warning: Profiler clears events at the end of each cycle.Only events from the current cycle will be reported.To keep events across cycles, set acc_events=True.\n",
      "  _warn_once(\n",
      "/workspace/efdl_hw/week05_fsdp/homework/.venv/lib/python3.12/site-packages/torch/profiler/profiler.py:217: UserWarning: Warning: Profiler clears events at the end of each cycle.Only events from the current cycle will be reported.To keep events across cycles, set acc_events=True.\n",
      "  _warn_once(\n",
      "[rank0]:[W227 19:16:23.978237903 unwind.cpp:216] Warning: Unsupported unwinding pattern: unknown op code 0x8 (function unwinderFor)\n",
      "[rank1]:[W227 19:16:23.978521528 unwind.cpp:216] Warning: Unsupported unwinding pattern: unknown op code 0x8 (function unwinderFor)\n",
      "[rank0]:[W227 19:16:26.740205403 unwind.cpp:216] Warning: Unsupported unwinding pattern: unknown op code 0x8 (function unwinderFor)\n",
      "[rank1]:[W227 19:16:26.740229993 unwind.cpp:216] Warning: Unsupported unwinding pattern: unknown op code 0x8 (function unwinderFor)\n",
      "2026-02-27 19:16:27,003 - __main__ - INFO - step:  1  loss: 11.8416  grad_norm:  9.7628\n",
      "2026-02-27 19:16:27,067 - __main__ - INFO - step:  1  loss: 11.8416  grad_norm:  9.7628\n",
      "2026-02-27 19:16:29,981 - __main__ - INFO - step:  2  loss:  6.6400  grad_norm:  9.4944\n",
      "2026-02-27 19:16:29,981 - __main__ - INFO - step:  2  loss:  6.6400  grad_norm:  9.4944\n",
      "2026-02-27 19:16:32,921 - __main__ - INFO - step:  3  loss:  5.6341  grad_norm: 11.8124\n",
      "2026-02-27 19:16:32,922 - __main__ - INFO - step:  3  loss:  5.6341  grad_norm: 11.8124\n",
      "2026-02-27 19:16:39,413 - __main__ - INFO - step:  4  loss:  5.3189  grad_norm: 18.9987\n",
      "2026-02-27 19:16:39,413 - __main__ - INFO - step:  4  loss:  5.3189  grad_norm: 18.9987\n",
      "2026-02-27 19:16:42,355 - __main__ - INFO - step:  5  loss:  4.9505  grad_norm: 14.6037\n",
      "2026-02-27 19:16:42,355 - __main__ - INFO - step:  5  loss:  4.9505  grad_norm: 14.6037\n"
     ]
    }
   ],
   "source": [
    "!uv run torchrun --standalone --nproc-per-node=2 train.py --fsdp fsdp2 --num-steps-to-profile 3 --snapshots-dir snapshots/fsdp2 --traces-dir traces/fsdp2 --model 1b --seq-len 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "480839da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0227 19:18:43.046000 129002 torch/distributed/run.py:852] \n",
      "W0227 19:18:43.046000 129002 torch/distributed/run.py:852] *****************************************\n",
      "W0227 19:18:43.046000 129002 torch/distributed/run.py:852] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0227 19:18:43.046000 129002 torch/distributed/run.py:852] *****************************************\n",
      "2026-02-27 19:18:48,851 - __main__ - INFO - model size: 1498482688 parameters.\n",
      "2026-02-27 19:18:48,853 - __main__ - INFO - model size: 1498482688 parameters.\n",
      "2026-02-27 19:18:48,910 - root - INFO - Loading tokenizer from tokenizer.json\n",
      "2026-02-27 19:18:48,913 - root - INFO - Preparing c4_test dataset from ./c4_test\n",
      "2026-02-27 19:18:48,913 - root - INFO - Loading tokenizer from tokenizer.json\n",
      "2026-02-27 19:18:48,915 - root - INFO - Preparing c4_test dataset from ./c4_test\n",
      "/workspace/efdl_hw/week05_fsdp/homework/.venv/lib/python3.12/site-packages/torch/profiler/profiler.py:217: UserWarning: Warning: Profiler clears events at the end of each cycle.Only events from the current cycle will be reported.To keep events across cycles, set acc_events=True.\n",
      "  _warn_once(\n",
      "/workspace/efdl_hw/week05_fsdp/homework/.venv/lib/python3.12/site-packages/torch/profiler/profiler.py:217: UserWarning: Warning: Profiler clears events at the end of each cycle.Only events from the current cycle will be reported.To keep events across cycles, set acc_events=True.\n",
      "  _warn_once(\n",
      "[rank1]:[W227 19:18:52.802593864 unwind.cpp:216] Warning: Unsupported unwinding pattern: unknown op code 0x8 (function unwinderFor)\n",
      "[rank0]:[W227 19:18:52.803344018 unwind.cpp:216] Warning: Unsupported unwinding pattern: unknown op code 0x8 (function unwinderFor)\n",
      "[rank1]:[W227 19:18:53.622359543 unwind.cpp:216] Warning: Unsupported unwinding pattern: unknown op code 0x8 (function unwinderFor)\n",
      "2026-02-27 19:18:53,061 - __main__ - INFO - step:  1  loss: 11.8416  grad_norm:  9.7628\n",
      "[rank0]:[W227 19:18:53.694786133 unwind.cpp:216] Warning: Unsupported unwinding pattern: unknown op code 0x8 (function unwinderFor)\n",
      "2026-02-27 19:18:53,134 - __main__ - INFO - step:  1  loss: 11.8416  grad_norm:  9.7628\n",
      "2026-02-27 19:18:56,137 - __main__ - INFO - step:  2  loss:  6.6400  grad_norm:  9.4944\n",
      "2026-02-27 19:18:56,137 - __main__ - INFO - step:  2  loss:  6.6400  grad_norm:  9.4944\n",
      "2026-02-27 19:18:59,142 - __main__ - INFO - step:  3  loss:  5.6341  grad_norm: 11.8124\n",
      "2026-02-27 19:18:59,142 - __main__ - INFO - step:  3  loss:  5.6341  grad_norm: 11.8124\n",
      "2026-02-27 19:19:06,041 - __main__ - INFO - step:  4  loss:  5.3189  grad_norm: 18.9987\n",
      "2026-02-27 19:19:06,040 - __main__ - INFO - step:  4  loss:  5.3189  grad_norm: 18.9987\n",
      "2026-02-27 19:19:09,064 - __main__ - INFO - step:  5  loss:  4.9505  grad_norm: 14.6037\n",
      "2026-02-27 19:19:09,064 - __main__ - INFO - step:  5  loss:  4.9505  grad_norm: 14.6037\n"
     ]
    }
   ],
   "source": [
    "!uv run torchrun --standalone --nproc-per-node=2 train.py --fsdp effdl --num-steps-to-profile 3 --snapshots-dir snapshots/effdl --traces-dir traces/effdl  --model 1b --seq-len 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b610001d",
   "metadata": {},
   "source": [
    "<img src=\"mem_effdl.png\" alt=\"Memory comparison\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090f378e",
   "metadata": {},
   "source": [
    "<img src=\"mem_fsdp2.png\" alt=\"Memory comparison\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06a5d00",
   "metadata": {},
   "source": [
    "как видно мемори снепшоты получаются очень похожими"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e01da9",
   "metadata": {},
   "source": [
    "<img src=\"prof_effdl.png\" alt=\"Memory comparison\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107dab90",
   "metadata": {},
   "source": [
    "<img src=\"prof_fsdp2.png\" alt=\"Memory comparison\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5084c7",
   "metadata": {},
   "source": [
    "также можно увидеть что профиль почти совпадает"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee6dfee",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
