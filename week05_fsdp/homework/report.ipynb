{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f77e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[31m                                                                     [100%]\u001b[0m\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m___________________ test_fsdp_with_itself[bfloat16-bfloat16] ___________________\u001b[0m\n",
      "\n",
      "param_dtype = 'bfloat16', reduce_dtype = 'bfloat16'\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mparam_dtype\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[94mNone\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mbfloat16\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mreduce_dtype\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mbfloat16\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_fsdp_with_itself\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        param_dtype: Literal[\u001b[33m\"\u001b[39;49;00m\u001b[33mbfloat16\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] | \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        reduce_dtype: Literal[\u001b[33m\"\u001b[39;49;00m\u001b[33mbfloat16\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] | \u001b[94mNone\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "    ):\u001b[90m\u001b[39;49;00m\n",
      ">       run_distributed_test(\u001b[90m\u001b[39;49;00m\n",
      "            _test_fsdp_with_itself,\u001b[90m\u001b[39;49;00m\n",
      "            param_dtype=param_dtype,\u001b[90m\u001b[39;49;00m\n",
      "            reduce_dtype=reduce_dtype,\u001b[90m\u001b[39;49;00m\n",
      "            world_size=\u001b[94m2\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtest.py\u001b[0m:116: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mtest.py\u001b[0m:82: in run_distributed_test\n",
      "    \u001b[0mmp.start_processes(  \u001b[90m# type: ignore[attr-defined,no-untyped-call]\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m.venv/lib/python3.12/site-packages/torch/multiprocessing/spawn.py\u001b[0m:296: in start_processes\n",
      "    \u001b[0m\u001b[94mwhile\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m context.join():\u001b[90m\u001b[39;49;00m\n",
      "              ^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <torch.multiprocessing.spawn.ProcessContext object at 0x7f2a450725d0>\n",
      "timeout = None, grace_period = None\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mjoin\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, timeout: \u001b[96mfloat\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m, grace_period: \u001b[96mfloat\u001b[39;49;00m | \u001b[94mNone\u001b[39;49;00m = \u001b[94mNone\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\"\"Join one or more processes within spawn context.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Attempt to join one or more processes in this spawn context.\u001b[39;49;00m\n",
      "    \u001b[33m    If one of them exited with a non-zero exit status, this function\u001b[39;49;00m\n",
      "    \u001b[33m    kills the remaining processes (optionally with a grace period)\u001b[39;49;00m\n",
      "    \u001b[33m    and raises an exception with the cause of the first process exiting.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns ``True`` if all processes have been joined successfully,\u001b[39;49;00m\n",
      "    \u001b[33m    ``False`` if there are more processes that need to be joined.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Args:\u001b[39;49;00m\n",
      "    \u001b[33m        timeout (float): Wait this long (in seconds) before giving up on waiting.\u001b[39;49;00m\n",
      "    \u001b[33m        grace_period (float): When any processes fail, wait this long (in seconds)\u001b[39;49;00m\n",
      "    \u001b[33m            for others to shutdown gracefully before terminating them. If they\u001b[39;49;00m\n",
      "    \u001b[33m            still don't exit, wait another grace period before killing them.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Ensure this function can be called even when we're done.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.sentinels) == \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Wait for any process to fail or all of them to succeed.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        ready = multiprocessing.connection.wait(\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mself\u001b[39;49;00m.sentinels.keys(),\u001b[90m\u001b[39;49;00m\n",
      "            timeout=timeout,\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        error_index = \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mfor\u001b[39;49;00m sentinel \u001b[95min\u001b[39;49;00m ready:\u001b[90m\u001b[39;49;00m\n",
      "            index = \u001b[96mself\u001b[39;49;00m.sentinels.pop(sentinel)\u001b[90m\u001b[39;49;00m\n",
      "            process = \u001b[96mself\u001b[39;49;00m.processes[index]\u001b[90m\u001b[39;49;00m\n",
      "            process.join()\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m process.exitcode != \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                error_index = index\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mbreak\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Return if there was no error.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m error_index \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Return whether or not all processes have been joined.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.sentinels) == \u001b[94m0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# An error occurred. Clean-up all processes before returning.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# First, allow a grace period for processes to shutdown themselves.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m grace_period \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mself\u001b[39;49;00m._join_procs_with_timeout(grace_period)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Then, terminate processes that are still alive. Try SIGTERM first.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mfor\u001b[39;49;00m process \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.processes:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m process.is_alive():\u001b[90m\u001b[39;49;00m\n",
      "                log.warning(\u001b[33m\"\u001b[39;49;00m\u001b[33mTerminating process \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m via signal SIGTERM\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, process.pid)\u001b[90m\u001b[39;49;00m\n",
      "                process.terminate()\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Try SIGKILL if the process isn't going down after another grace_period.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# The reason is related to python signal handling is limited\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# to main thread and if that is in c/c++ land and stuck it won't\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# to handle it. We have seen processes getting stuck not handling\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# SIGTERM for the above reason.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m._join_procs_with_timeout(\u001b[94m30\u001b[39;49;00m \u001b[94mif\u001b[39;49;00m grace_period \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m \u001b[94melse\u001b[39;49;00m grace_period)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mfor\u001b[39;49;00m process \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.processes:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m process.is_alive():\u001b[90m\u001b[39;49;00m\n",
      "                log.warning(\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mUnable to shutdown process \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m via SIGTERM , forcefully exiting via SIGKILL\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    process.pid,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "                process.kill()\u001b[90m\u001b[39;49;00m\n",
      "            process.join()\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# The file will only be created if the process crashed.\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        failed_process = \u001b[96mself\u001b[39;49;00m.processes[error_index]\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m os.access(\u001b[96mself\u001b[39;49;00m.error_files[error_index], os.R_OK):\u001b[90m\u001b[39;49;00m\n",
      "            exitcode = \u001b[96mself\u001b[39;49;00m.processes[error_index].exitcode\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m exitcode < \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    name = signal.Signals(-exitcode).name\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mexcept\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    name = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m<Unknown signal \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m-exitcode\u001b[33m}\u001b[39;49;00m\u001b[33m>\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m ProcessExitedException(\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mprocess \u001b[39;49;00m\u001b[33m{\u001b[39;49;00merror_index\u001b[33m:\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m terminated with signal \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mname\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    error_index=error_index,\u001b[90m\u001b[39;49;00m\n",
      "                    error_pid=failed_process.pid,\u001b[90m\u001b[39;49;00m\n",
      "                    exit_code=exitcode,\u001b[90m\u001b[39;49;00m\n",
      "                    signal_name=name,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mraise\u001b[39;49;00m ProcessExitedException(\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mprocess \u001b[39;49;00m\u001b[33m{\u001b[39;49;00merror_index\u001b[33m:\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m terminated with exit code \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mexitcode\u001b[33m:\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                    error_index=error_index,\u001b[90m\u001b[39;49;00m\n",
      "                    error_pid=failed_process.pid,\u001b[90m\u001b[39;49;00m\n",
      "                    exit_code=exitcode,\u001b[90m\u001b[39;49;00m\n",
      "                )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mwith\u001b[39;49;00m \u001b[96mopen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.error_files[error_index], \u001b[33m\"\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[94mas\u001b[39;49;00m fh:\u001b[90m\u001b[39;49;00m\n",
      "            original_trace = pickle.load(fh)\u001b[90m\u001b[39;49;00m\n",
      "        msg = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m-- Process \u001b[39;49;00m\u001b[33m{\u001b[39;49;00merror_index\u001b[33m:\u001b[39;49;00m\u001b[33md\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m terminated with the following error:\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        msg += original_trace\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m ProcessRaisedException(msg, error_index, failed_process.pid)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       torch.multiprocessing.spawn.ProcessRaisedException: \u001b[0m\n",
      "\u001b[1m\u001b[31mE       \u001b[0m\n",
      "\u001b[1m\u001b[31mE       -- Process 0 terminated with the following error:\u001b[0m\n",
      "\u001b[1m\u001b[31mE       Traceback (most recent call last):\u001b[0m\n",
      "\u001b[1m\u001b[31mE         File \"/workspace/efdl_hw/week05_fsdp/homework/.venv/lib/python3.12/site-packages/torch/multiprocessing/spawn.py\", line 87, in _wrap\u001b[0m\n",
      "\u001b[1m\u001b[31mE           fn(i, *args)\u001b[0m\n",
      "\u001b[1m\u001b[31mE         File \"/workspace/efdl_hw/week05_fsdp/homework/test.py\", line 69, in _run_test\u001b[0m\n",
      "\u001b[1m\u001b[31mE           func(*func_args, **func_kwargs)\u001b[0m\n",
      "\u001b[1m\u001b[31mE         File \"/workspace/efdl_hw/week05_fsdp/homework/test.py\", line 164, in _test_fsdp_with_itself\u001b[0m\n",
      "\u001b[1m\u001b[31mE           assert fsdp_loss == effdl_loss\u001b[0m\n",
      "\u001b[1m\u001b[31mE                  ^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "\u001b[1m\u001b[31mE       AssertionError\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m.venv/lib/python3.12/site-packages/torch/multiprocessing/spawn.py\u001b[0m:211: ProcessRaisedException\n",
      "----------------------------- Captured stderr call -----------------------------\n",
      "2026-02-26 21:02:08,649 - train - INFO - model size: 6163712 parameters.\n",
      "2026-02-26 21:02:08,666 - train - INFO - model size: 6163712 parameters.\n",
      "2026-02-26 21:02:08,679 - root - INFO - Loading tokenizer from tokenizer.json\n",
      "2026-02-26 21:02:08,681 - root - INFO - Preparing c4_test dataset from ./c4_test\n",
      "2026-02-26 21:02:08,695 - root - INFO - Loading tokenizer from tokenizer.json\n",
      "2026-02-26 21:02:08,697 - root - INFO - Preparing c4_test dataset from ./c4_test\n",
      "2026-02-26 21:02:10,432 - train - INFO - step:  1  loss:  7.7014  grad_norm:  2.2645\n",
      "2026-02-26 21:02:10,433 - train - INFO - step:  1  loss:  7.7014  grad_norm:  2.2645\n",
      "2026-02-26 21:02:10,473 - train - INFO - step:  2  loss:  6.3580  grad_norm:  2.8387\n",
      "2026-02-26 21:02:10,474 - train - INFO - step:  2  loss:  6.3580  grad_norm:  2.8387\n",
      "2026-02-26 21:02:10,512 - train - INFO - step:  3  loss:  5.8353  grad_norm:  2.8503\n",
      "2026-02-26 21:02:10,513 - train - INFO - step:  3  loss:  5.8353  grad_norm:  2.8503\n",
      "2026-02-26 21:02:10,550 - train - INFO - step:  4  loss:  5.2044  grad_norm:  3.1454\n",
      "2026-02-26 21:02:10,553 - train - INFO - step:  4  loss:  5.2044  grad_norm:  3.1454\n",
      "2026-02-26 21:02:10,592 - train - INFO - step:  5  loss:  4.8257  grad_norm:  2.8328\n",
      "2026-02-26 21:02:10,595 - train - INFO - step:  5  loss:  4.8257  grad_norm:  2.8328\n",
      "2026-02-26 21:02:10,600 - train - INFO - model size: 6163712 parameters.\n",
      "2026-02-26 21:02:10,603 - train - INFO - model size: 6163712 parameters.\n",
      "2026-02-26 21:02:10,617 - root - INFO - Loading tokenizer from tokenizer.json\n",
      "2026-02-26 21:02:10,619 - root - INFO - Preparing c4_test dataset from ./c4_test\n",
      "2026-02-26 21:02:10,620 - root - INFO - Loading tokenizer from tokenizer.json\n",
      "2026-02-26 21:02:10,621 - root - INFO - Preparing c4_test dataset from ./c4_test\n",
      "2026-02-26 21:02:10,688 - train - INFO - step:  1  loss:  7.7014  grad_norm:  2.2645\n",
      "2026-02-26 21:02:10,690 - train - INFO - step:  1  loss:  7.7014  grad_norm:  2.2645\n",
      "2026-02-26 21:02:10,732 - train - INFO - step:  2  loss:  6.3584  grad_norm:  2.8384\n",
      "2026-02-26 21:02:10,734 - train - INFO - step:  2  loss:  6.3584  grad_norm:  2.8384\n",
      "2026-02-26 21:02:10,779 - train - INFO - step:  3  loss:  5.8352  grad_norm:  2.8503\n",
      "2026-02-26 21:02:10,780 - train - INFO - step:  3  loss:  5.8352  grad_norm:  2.8503\n",
      "2026-02-26 21:02:10,825 - train - INFO - step:  4  loss:  5.2042  grad_norm:  3.1454\n",
      "2026-02-26 21:02:10,825 - train - INFO - step:  4  loss:  5.2042  grad_norm:  3.1454\n",
      "2026-02-26 21:02:10,872 - train - INFO - step:  5  loss:  4.8257  grad_norm:  2.8325\n",
      "2026-02-26 21:02:10,873 - train - INFO - step:  5  loss:  4.8257  grad_norm:  2.8325\n",
      "W0226 21:02:12.468000 66785 .venv/lib/python3.12/site-packages/torch/multiprocessing/spawn.py:165] Terminating process 67359 via signal SIGTERM\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      ".venv/lib/python3.12/site-packages/torch/jit/_script.py:362: 14 warnings\n",
      "  /workspace/efdl_hw/week05_fsdp/homework/.venv/lib/python3.12/site-packages/torch/jit/_script.py:362: DeprecationWarning: `torch.jit.script_method` is deprecated. Please switch to `torch.compile` or `torch.export`.\n",
      "    warnings.warn(\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m test.py::\u001b[1mtest_fsdp_with_itself[bfloat16-bfloat16]\u001b[0m - torch.multiprocessing.spawn.ProcessRaisedException: \n",
      "\u001b[31m\u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m3 passed\u001b[0m, \u001b[33m14 warnings\u001b[0m\u001b[31m in 41.68s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv run python -m pytest \"test.py::test_fsdp_with_itself\" -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98ad77d",
   "metadata": {},
   "source": [
    "**как можно заметить fsdp2 сам против себя не выдает стабильные результаты** так что поменял тесты чтобы они принимали погрешность до 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a4a9468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33m                                                                     [100%]\u001b[0m\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      ".venv/lib/python3.12/site-packages/torch/jit/_script.py:362: 14 warnings\n",
      "  /workspace/efdl_hw/week05_fsdp/homework/.venv/lib/python3.12/site-packages/torch/jit/_script.py:362: DeprecationWarning: `torch.jit.script_method` is deprecated. Please switch to `torch.compile` or `torch.export`.\n",
      "    warnings.warn(\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m\u001b[32m4 passed\u001b[0m, \u001b[33m\u001b[1m14 warnings\u001b[0m\u001b[33m in 42.10s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv run python -m pytest \"test.py::test_fsdp\" -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bec8da32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0226 21:14:14.450000 69311 torch/distributed/run.py:852] \n",
      "W0226 21:14:14.450000 69311 torch/distributed/run.py:852] *****************************************\n",
      "W0226 21:14:14.450000 69311 torch/distributed/run.py:852] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0226 21:14:14.450000 69311 torch/distributed/run.py:852] *****************************************\n",
      "2026-02-26 21:14:19,947 - __main__ - INFO - model size: 6163712 parameters.\n",
      "2026-02-26 21:14:19,977 - root - INFO - Loading tokenizer from tokenizer.json\n",
      "2026-02-26 21:14:19,980 - root - INFO - Preparing c4_test dataset from ./c4_test\n",
      "/workspace/efdl_hw/week05_fsdp/homework/.venv/lib/python3.12/site-packages/torch/profiler/profiler.py:217: UserWarning: Warning: Profiler clears events at the end of each cycle.Only events from the current cycle will be reported.To keep events across cycles, set acc_events=True.\n",
      "  _warn_once(\n",
      "2026-02-26 21:14:20,014 - __main__ - INFO - model size: 6163712 parameters.\n",
      "2026-02-26 21:14:20,051 - root - INFO - Loading tokenizer from tokenizer.json\n",
      "2026-02-26 21:14:20,053 - root - INFO - Preparing c4_test dataset from ./c4_test\n",
      "/workspace/efdl_hw/week05_fsdp/homework/.venv/lib/python3.12/site-packages/torch/profiler/profiler.py:217: UserWarning: Warning: Profiler clears events at the end of each cycle.Only events from the current cycle will be reported.To keep events across cycles, set acc_events=True.\n",
      "  _warn_once(\n",
      "[rank0]:[W226 21:14:20.034868224 unwind.cpp:216] Warning: Unsupported unwinding pattern: unknown op code 0x8 (function unwinderFor)\n",
      "[rank1]:[W226 21:14:20.043434380 unwind.cpp:216] Warning: Unsupported unwinding pattern: unknown op code 0x8 (function unwinderFor)\n",
      "[rank0]:[W226 21:14:20.353170024 unwind.cpp:216] Warning: Unsupported unwinding pattern: unknown op code 0x8 (function unwinderFor)\n",
      "[rank1]:[W226 21:14:20.354895716 unwind.cpp:216] Warning: Unsupported unwinding pattern: unknown op code 0x8 (function unwinderFor)\n",
      "2026-02-26 21:14:21,117 - __main__ - INFO - step:  1  loss:  7.7016  grad_norm:  2.2632\n",
      "2026-02-26 21:14:21,158 - __main__ - INFO - step:  1  loss:  7.7016  grad_norm:  2.2632\n",
      "2026-02-26 21:14:21,231 - __main__ - INFO - step:  2  loss:  6.3574  grad_norm:  2.8391\n",
      "2026-02-26 21:14:21,232 - __main__ - INFO - step:  2  loss:  6.3574  grad_norm:  2.8391\n",
      "2026-02-26 21:14:21,300 - __main__ - INFO - step:  3  loss:  5.8339  grad_norm:  2.8520\n",
      "2026-02-26 21:14:21,301 - __main__ - INFO - step:  3  loss:  5.8339  grad_norm:  2.8520\n",
      "2026-02-26 21:14:24,529 - __main__ - INFO - step:  4  loss:  5.2011  grad_norm:  3.1478\n",
      "2026-02-26 21:14:24,534 - __main__ - INFO - step:  4  loss:  5.2011  grad_norm:  3.1478\n",
      "2026-02-26 21:14:24,608 - __main__ - INFO - step:  5  loss:  4.8225  grad_norm:  2.8337\n",
      "2026-02-26 21:14:24,612 - __main__ - INFO - step:  5  loss:  4.8225  grad_norm:  2.8337\n"
     ]
    }
   ],
   "source": [
    "!uv run torchrun --standalone --nproc-per-node=2 train.py --fsdp fsdp2 --num-steps-to-profile 3 --snapshots-dir snapshots/fsdp2 --traces-dir traces/fsdp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "480839da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0226 21:14:29.651000 69463 torch/distributed/run.py:852] \n",
      "W0226 21:14:29.651000 69463 torch/distributed/run.py:852] *****************************************\n",
      "W0226 21:14:29.651000 69463 torch/distributed/run.py:852] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0226 21:14:29.651000 69463 torch/distributed/run.py:852] *****************************************\n",
      "2026-02-26 21:14:35,337 - __main__ - INFO - model size: 6163712 parameters.\n",
      "2026-02-26 21:14:35,367 - root - INFO - Loading tokenizer from tokenizer.json\n",
      "2026-02-26 21:14:35,369 - root - INFO - Preparing c4_test dataset from ./c4_test\n",
      "/workspace/efdl_hw/week05_fsdp/homework/.venv/lib/python3.12/site-packages/torch/profiler/profiler.py:217: UserWarning: Warning: Profiler clears events at the end of each cycle.Only events from the current cycle will be reported.To keep events across cycles, set acc_events=True.\n",
      "  _warn_once(\n",
      "2026-02-26 21:14:35,781 - __main__ - INFO - model size: 6163712 parameters.\n",
      "2026-02-26 21:14:35,810 - root - INFO - Loading tokenizer from tokenizer.json\n",
      "2026-02-26 21:14:35,813 - root - INFO - Preparing c4_test dataset from ./c4_test\n",
      "/workspace/efdl_hw/week05_fsdp/homework/.venv/lib/python3.12/site-packages/torch/profiler/profiler.py:217: UserWarning: Warning: Profiler clears events at the end of each cycle.Only events from the current cycle will be reported.To keep events across cycles, set acc_events=True.\n",
      "  _warn_once(\n",
      "[rank1]:[W226 21:14:36.100739605 unwind.cpp:216] Warning: Unsupported unwinding pattern: unknown op code 0x8 (function unwinderFor)\n",
      "[rank0]:[W226 21:14:36.102900358 unwind.cpp:216] Warning: Unsupported unwinding pattern: unknown op code 0x8 (function unwinderFor)\n",
      "[rank0]:[W226 21:14:36.448487029 unwind.cpp:216] Warning: Unsupported unwinding pattern: unknown op code 0x8 (function unwinderFor)\n",
      "2026-02-26 21:14:36,876 - __main__ - INFO - step:  1  loss:  7.7016  grad_norm:  2.2632\n",
      "[rank1]:[W226 21:14:36.461895857 unwind.cpp:216] Warning: Unsupported unwinding pattern: unknown op code 0x8 (function unwinderFor)\n",
      "2026-02-26 21:14:36,890 - __main__ - INFO - step:  1  loss:  7.7016  grad_norm:  2.2632\n",
      "2026-02-26 21:14:37,000 - __main__ - INFO - step:  2  loss:  6.3574  grad_norm:  2.8391\n",
      "2026-02-26 21:14:37,005 - __main__ - INFO - step:  2  loss:  6.3574  grad_norm:  2.8391\n",
      "2026-02-26 21:14:37,115 - __main__ - INFO - step:  3  loss:  5.8339  grad_norm:  2.8520\n",
      "2026-02-26 21:14:37,117 - __main__ - INFO - step:  3  loss:  5.8339  grad_norm:  2.8520\n",
      "2026-02-26 21:14:39,994 - __main__ - INFO - step:  4  loss:  5.2011  grad_norm:  3.1478\n",
      "2026-02-26 21:14:39,998 - __main__ - INFO - step:  4  loss:  5.2011  grad_norm:  3.1478\n",
      "2026-02-26 21:14:40,086 - __main__ - INFO - step:  5  loss:  4.8225  grad_norm:  2.8337\n",
      "2026-02-26 21:14:40,090 - __main__ - INFO - step:  5  loss:  4.8225  grad_norm:  2.8337\n"
     ]
    }
   ],
   "source": [
    "!uv run torchrun --standalone --nproc-per-node=2 train.py --fsdp effdl --num-steps-to-profile 3 --snapshots-dir snapshots/effdl --traces-dir traces/effdl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b7f2ee",
   "metadata": {},
   "source": [
    "<img src=\"images/image.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6819a9",
   "metadata": {},
   "source": [
    "<img src=\"images/image2.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06a5d00",
   "metadata": {},
   "source": [
    "как видно мемори снепшоты получаются очень похожими"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e01da9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
