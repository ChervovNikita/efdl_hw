{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7192a0e",
   "metadata": {},
   "source": [
    "### Свой профайлер"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36510c8c",
   "metadata": {},
   "source": [
    "гугл диск говорит, что ресурс нельзя забрать, поэтому взял clothing-dataset с гитхаба переделал под нужный формат - папка дата и внутри папка train\n",
    "\n",
    "также почему-то 5 картинок не было поэтому из csv удалил их\n",
    "\n",
    "```\n",
    "d028580f-9a98-4fb5-a6c9-5dc362ad3f09\n",
    "1d0129a1-f29a-4a3f-b103-f651176183eb\n",
    "784d67d4-b95e-4abb-baf7-8024f18dc3c8\n",
    "c60e486d-10ed-4f64-abab-5bb698c736dd\n",
    "040d73b7-21b5-4cf2-84fc-e1a80231b202\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94933f5f",
   "metadata": {},
   "source": [
    "далее написал профайлер, каждый шаг обновляю дикт в котором храню куда события для pre forward, post forward, pre backward, post backward (только если сейчас не wait шаг)\n",
    "\n",
    "далее когда доходит до profiler.step() закидываю все эти события в tmp список и обновляю дикт\n",
    "\n",
    "периодически проверяю что событие из tmp завершилось и перекидываю его тогда в основной список\n",
    "\n",
    "во время to_perfetto проверяю что нет незавершенных события и кидаю ворнинг если есть (надо sync сделать)\n",
    "\n",
    "получились следующие резы в perfetto:\n",
    "\n",
    "на трейне\n",
    "\n",
    "<img src=\"image_train.jpg\" width=\"1000\">\n",
    "\n",
    "на валидации\n",
    "\n",
    "<img src=\"image_val.jpg\" width=\"1000\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffde3b7e",
   "metadata": {},
   "source": [
    "тем временем у профайлера торча\n",
    "\n",
    "на трейне\n",
    "\n",
    "<img src=\"image_train_torch.jpg\" width=\"1000\">\n",
    "\n",
    "на валидации\n",
    "\n",
    "<img src=\"image_val_torch.jpg\" width=\"1000\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaf000a",
   "metadata": {},
   "source": [
    "на валидации видим тоже самое но у торча более подробно, но вот на трейне у них весь backward засунут в один блок\n",
    "\n",
    "также у них есть на cpu профайлер поэтому можно легко увидеть основную проблему с данным обучением\n",
    "\n",
    "<img src=\"image_val_torch2.jpg\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4c55ca",
   "metadata": {},
   "source": [
    "как видно например на валидации, обучение занимает супер мало времени и почти все время уходит на даталоадер, но про это во второй части"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b4eb76",
   "metadata": {},
   "source": [
    "### Проблемы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec873515",
   "metadata": {},
   "source": [
    "1. у нас как я показал на прошлом скрине ботлнек в даталоадере, при этом он ранится в один поток, поставил 64\n",
    "\n",
    "также добавил чтобы мы сразу считали в торче и не было оверхед на перевод из PIL в torch (там если посмотреть PIL считывание занимало где-то 1/4 от одного getitem, но хз засчитывается ли это за баг)\n",
    "\n",
    "стало выглядить вот так"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5671b72c",
   "metadata": {},
   "source": [
    "<img src=\"train_log_bug1.jpg\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b9399d",
   "metadata": {},
   "source": [
    "2. чтобы он сразу перекидывал в нужную память добавляем pin memory в даталоадер\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba198ec4",
   "metadata": {},
   "source": [
    "<img src=\"train_log_bug2.jpg\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4514fd88",
   "metadata": {},
   "source": [
    "3. перед форвардом у нас есть куда синхронайз нужно добавить non blocking в .to()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"train_log_bug33.jpg\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5346293b",
   "metadata": {},
   "source": [
    "4. прошлое улучшение убрало синк но не ускорило тк у нас есть еще один\n",
    "\n",
    "также между форвардом и беквардом у нас есть синхронизация, оставляем detach() но убираем .item() и делаем его в конце эпохи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23cc7de",
   "metadata": {},
   "source": [
    "<img src=\"train_log_bug4.jpg\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8838a331",
   "metadata": {},
   "source": [
    "5. ну тут без профайлера но наша валидация делается с подсчемтом градиента так что добавляем with torch.no_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36e2c13",
   "metadata": {},
   "source": [
    "6. и еще одна проблема тоже не связанная с профайлером, но мы считаем все в fp32 так что добавляем скейлер\n",
    "\n",
    "в итоге профайлер показывает вот такую картинку"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3adadb4",
   "metadata": {},
   "source": [
    "<img src=\"train_log_bug6.jpg\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6576478e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
