{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65f594e7",
   "metadata": {},
   "source": [
    "**сначала надо скачать викитекст в корень**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2733b1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./task2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4721b9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/efdl_hw/week02_fast_pipelines/homework/venv/lib/python3.11/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from run_epoch import run_epoch, DataMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6f1fd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:10<00:00, 1832.01it/s]\n",
      "100%|██████████| 20000/20000 [00:12<00:00, 1648.43it/s]\n",
      "/workspace/efdl_hw/week02_fast_pipelines/homework/./task2/run_epoch.py:84: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "Loss: 5.7351: 100%|██████████| 2500/2500 [03:28<00:00, 11.98it/s]\n"
     ]
    }
   ],
   "source": [
    "run_epoch(DataMode.BRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f80374d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:06<00:00, 2867.36it/s]\n",
      "100%|██████████| 20000/20000 [00:08<00:00, 2372.82it/s]\n",
      "/workspace/efdl_hw/week02_fast_pipelines/homework/./task2/run_epoch.py:84: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "Loss: 5.7383: 100%|██████████| 2500/2500 [01:57<00:00, 21.19it/s]\n"
     ]
    }
   ],
   "source": [
    "run_epoch(DataMode.BIG_BRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd01e557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:06<00:00, 2880.01it/s]\n",
      "100%|██████████| 20000/20000 [00:08<00:00, 2313.23it/s]\n",
      "Loss: 5.0688: 100%|██████████| 2657/2657 [01:26<00:00, 30.70it/s]\n"
     ]
    }
   ],
   "source": [
    "run_epoch(DataMode.ULTRA_BIG_BRAIN, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c153666b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:06<00:00, 2876.91it/s]\n",
      "100%|██████████| 20000/20000 [00:08<00:00, 2361.59it/s]\n",
      "Loss: 5.1442: 100%|██████████| 2558/2558 [01:24<00:00, 30.21it/s]\n"
     ]
    }
   ],
   "source": [
    "run_epoch(DataMode.ULTRA_BIG_BRAIN, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bf5d80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:07<00:00, 2820.50it/s]\n",
      "100%|██████████| 20000/20000 [00:08<00:00, 2343.08it/s]\n",
      "Loss: 5.1836: 100%|██████████| 2531/2531 [01:24<00:00, 30.01it/s]\n"
     ]
    }
   ],
   "source": [
    "run_epoch(DataMode.ULTRA_BIG_BRAIN, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3ec1be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:07<00:00, 2823.58it/s]\n",
      "100%|██████████| 20000/20000 [00:08<00:00, 2299.68it/s]\n",
      "Loss: 5.0701: 100%|██████████| 2516/2516 [01:23<00:00, 30.13it/s]\n"
     ]
    }
   ],
   "source": [
    "run_epoch(DataMode.ULTRA_BIG_BRAIN, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f234bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:06<00:00, 2874.34it/s]\n",
      "100%|██████████| 20000/20000 [00:08<00:00, 2374.81it/s]\n",
      "Loss: 5.3147: 100%|██████████| 2504/2504 [01:24<00:00, 29.48it/s]\n"
     ]
    }
   ],
   "source": [
    "run_epoch(DataMode.ULTRA_BIG_BRAIN, k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a2c8d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:07<00:00, 2803.25it/s]\n",
      "100%|██████████| 20000/20000 [00:08<00:00, 2246.50it/s]\n",
      "Loss: 5.7417: 100%|██████████| 2500/2500 [01:57<00:00, 21.23it/s]\n"
     ]
    }
   ],
   "source": [
    "run_epoch(DataMode.ULTRA_BIG_BRAIN, k=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59811d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:07<00:00, 2785.48it/s]\n",
      "100%|██████████| 20000/20000 [00:08<00:00, 2295.99it/s]\n",
      "/workspace/efdl_hw/week02_fast_pipelines/homework/./task2/dataset.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.seq_masks.append(torch.tensor(seq_mask))\n",
      "Loss: 5.731: 100%|██████████| 6230/6230 [03:15<00:00, 31.88it/s] \n"
     ]
    }
   ],
   "source": [
    "run_epoch(DataMode.ULTRA_DUPER_BIG_BRAIN_NAIVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "648f7f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:07<00:00, 2738.48it/s]\n",
      "100%|██████████| 20000/20000 [00:08<00:00, 2308.30it/s]\n",
      "100%|██████████| 39995/39995 [00:37<00:00, 1055.67it/s]\n",
      "/workspace/efdl_hw/week02_fast_pipelines/homework/./task2/dataset.py:157: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.seq_masks.append(torch.tensor(seq_mask))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[624, 16], [351, 289], [289, 289, 62], [251, 251, 138], [230, 230, 180], [212, 212, 212, 4], [189, 189, 189, 73], [171, 171, 171, 127], [155, 155, 155, 155, 20], [137, 137, 137, 137, 92], [117, 117, 117, 117, 117, 55], [95, 95, 95, 95, 95, 95, 70], [29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 5.7424: 100%|██████████| 6225/6225 [03:15<00:00, 31.87it/s]\n"
     ]
    }
   ],
   "source": [
    "run_epoch(DataMode.ULTRA_DUPER_BIG_BRAIN_FFD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea48ece2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:07<00:00, 2717.22it/s]\n",
      "100%|██████████| 20000/20000 [00:08<00:00, 2305.60it/s]\n",
      "100%|██████████| 39995/39995 [00:00<00:00, 58666.43it/s]\n",
      "/workspace/efdl_hw/week02_fast_pipelines/homework/./task2/dataset.py:253: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.seq_masks.append(torch.tensor(seq_mask))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[624, 16], [351, 289], [289, 289, 62], [251, 251, 138], [230, 230, 180], [212, 212, 212, 4], [189, 189, 189, 73], [171, 171, 171, 127], [155, 155, 155, 155, 20], [137, 137, 137, 137, 92], [117, 117, 117, 117, 117, 55], [95, 95, 95, 95, 95, 95, 70], [29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 5.6895: 100%|██████████| 6225/6225 [03:14<00:00, 32.05it/s]\n"
     ]
    }
   ],
   "source": [
    "run_epoch(DataMode.ULTRA_DUPER_BIG_BRAIN_OBFD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b36803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "brain_times = pickle.load(open('BRAIN.pkl', 'rb'))['times']\n",
    "big_brain_times = pickle.load(open('BIG_BRAIN.pkl', 'rb'))['times']\n",
    "ultra_big_brain_k1_times = pickle.load(open('ULTRA_BIG_BRAIN_k1.pkl', 'rb'))['times']\n",
    "ultra_big_brain_k5_times = pickle.load(open('ULTRA_BIG_BRAIN_k5.pkl', 'rb'))['times']\n",
    "ultra_big_brain_k10_times = pickle.load(open('ULTRA_BIG_BRAIN_k10.pkl', 'rb'))['times']\n",
    "ultra_big_brain_k20_times = pickle.load(open('ULTRA_BIG_BRAIN_k20.pkl', 'rb'))['times']\n",
    "ultra_big_brain_k50_times = pickle.load(open('ULTRA_BIG_BRAIN_k50.pkl', 'rb'))['times']\n",
    "ultra_big_brain_k640_times = pickle.load(open('ULTRA_BIG_BRAIN_k640.pkl', 'rb'))['times']\n",
    "ultra_duper_big_brain_naive_times = pickle.load(open('ULTRA_DUPER_BIG_BRAIN_NAIVE.pkl', 'rb'))['times']\n",
    "ultra_duper_big_brain_ffd_times = pickle.load(open('ULTRA_DUPER_BIG_BRAIN_FFD.pkl', 'rb'))['times']\n",
    "ultra_duper_big_brain_obfd_times = pickle.load(open('ULTRA_DUPER_BIG_BRAIN_OBFD.pkl', 'rb'))['times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce480537",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_times = brain_times[100:]\n",
    "big_brain_times = big_brain_times[100:]\n",
    "ultra_big_brain_k1_times = ultra_big_brain_k1_times[100:]\n",
    "ultra_big_brain_k5_times = ultra_big_brain_k5_times[100:]\n",
    "ultra_big_brain_k10_times = ultra_big_brain_k10_times[100:]\n",
    "ultra_big_brain_k20_times = ultra_big_brain_k20_times[100:]\n",
    "ultra_big_brain_k50_times = ultra_big_brain_k50_times[100:]\n",
    "ultra_big_brain_k640_times = ultra_big_brain_k640_times[100:]\n",
    "ultra_duper_big_brain_naive_times = ultra_duper_big_brain_naive_times[100:]\n",
    "ultra_duper_big_brain_ffd_times = ultra_duper_big_brain_ffd_times[100:]\n",
    "ultra_duper_big_brain_obfd_times = ultra_duper_big_brain_obfd_times[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51381b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "algo = [\n",
    "    'brain', 'big_brain', 'ultra_big_brain_k1', 'ultra_big_brain_k5', 'ultra_big_brain_k10', 'ultra_big_brain_k20', 'ultra_big_brain_k50', 'ultra_big_brain_k640', 'ultra_duper_big_brain_naive', 'ultra_duper_big_brain_ffd', 'ultra_duper_big_brain_obfd'\n",
    "]\n",
    "min_time = [\n",
    "    min(brain_times), min(big_brain_times), min(ultra_big_brain_k1_times), min(ultra_big_brain_k5_times), min(ultra_big_brain_k10_times), min(ultra_big_brain_k20_times), min(ultra_big_brain_k50_times), min(ultra_big_brain_k640_times), min(ultra_duper_big_brain_naive_times), min(ultra_duper_big_brain_ffd_times), min(ultra_duper_big_brain_obfd_times)\n",
    "]\n",
    "max_time = [\n",
    "    max(brain_times), max(big_brain_times), max(ultra_big_brain_k1_times), max(ultra_big_brain_k5_times), max(ultra_big_brain_k10_times), max(ultra_big_brain_k20_times), max(ultra_big_brain_k50_times), max(ultra_big_brain_k640_times), max(ultra_duper_big_brain_naive_times), max(ultra_duper_big_brain_ffd_times), max(ultra_duper_big_brain_obfd_times)\n",
    "]\n",
    "mean_time = [\n",
    "    np.mean(brain_times), np.mean(big_brain_times), np.mean(ultra_big_brain_k1_times), np.mean(ultra_big_brain_k5_times), np.mean(ultra_big_brain_k10_times), np.mean(ultra_big_brain_k20_times), np.mean(ultra_big_brain_k50_times), np.mean(ultra_big_brain_k640_times), np.mean(ultra_duper_big_brain_naive_times), np.mean(ultra_duper_big_brain_ffd_times), np.mean(ultra_duper_big_brain_obfd_times)\n",
    "]\n",
    "\n",
    "median_time = [\n",
    "    np.median(brain_times), np.median(big_brain_times), np.median(ultra_big_brain_k1_times), np.median(ultra_big_brain_k5_times), np.median(ultra_big_brain_k10_times), np.median(ultra_big_brain_k20_times), np.median(ultra_big_brain_k50_times), np.median(ultra_big_brain_k640_times), np.median(ultra_duper_big_brain_naive_times), np.median(ultra_duper_big_brain_ffd_times), np.median(ultra_duper_big_brain_obfd_times)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03e6fe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'algo': algo,\n",
    "    'min_time': min_time,\n",
    "    'max_time': max_time,\n",
    "    'mean_time': mean_time,\n",
    "    'median_time': median_time\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adc46528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo</th>\n",
       "      <th>min_time</th>\n",
       "      <th>max_time</th>\n",
       "      <th>mean_time</th>\n",
       "      <th>median_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brain</td>\n",
       "      <td>0.069699</td>\n",
       "      <td>0.085683</td>\n",
       "      <td>0.082124</td>\n",
       "      <td>0.082118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>big_brain</td>\n",
       "      <td>0.026524</td>\n",
       "      <td>0.084208</td>\n",
       "      <td>0.046626</td>\n",
       "      <td>0.045763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ultra_big_brain_k1</td>\n",
       "      <td>0.006707</td>\n",
       "      <td>0.088893</td>\n",
       "      <td>0.032033</td>\n",
       "      <td>0.028733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ultra_big_brain_k5</td>\n",
       "      <td>0.009163</td>\n",
       "      <td>0.183236</td>\n",
       "      <td>0.032594</td>\n",
       "      <td>0.029287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ultra_big_brain_k10</td>\n",
       "      <td>0.009920</td>\n",
       "      <td>0.100879</td>\n",
       "      <td>0.032920</td>\n",
       "      <td>0.030093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ultra_big_brain_k20</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.105579</td>\n",
       "      <td>0.032701</td>\n",
       "      <td>0.030170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ultra_big_brain_k50</td>\n",
       "      <td>0.010104</td>\n",
       "      <td>0.093079</td>\n",
       "      <td>0.033434</td>\n",
       "      <td>0.032799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ultra_big_brain_k640</td>\n",
       "      <td>0.027681</td>\n",
       "      <td>0.084502</td>\n",
       "      <td>0.046516</td>\n",
       "      <td>0.045551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ultra_duper_big_brain_naive</td>\n",
       "      <td>0.010675</td>\n",
       "      <td>0.079290</td>\n",
       "      <td>0.030365</td>\n",
       "      <td>0.022841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ultra_duper_big_brain_ffd</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.067300</td>\n",
       "      <td>0.030355</td>\n",
       "      <td>0.022893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ultra_duper_big_brain_obfd</td>\n",
       "      <td>0.020519</td>\n",
       "      <td>0.075266</td>\n",
       "      <td>0.030239</td>\n",
       "      <td>0.022873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           algo  min_time  max_time  mean_time  median_time\n",
       "0                         brain  0.069699  0.085683   0.082124     0.082118\n",
       "1                     big_brain  0.026524  0.084208   0.046626     0.045763\n",
       "2            ultra_big_brain_k1  0.006707  0.088893   0.032033     0.028733\n",
       "3            ultra_big_brain_k5  0.009163  0.183236   0.032594     0.029287\n",
       "4           ultra_big_brain_k10  0.009920  0.100879   0.032920     0.030093\n",
       "5           ultra_big_brain_k20  0.010192  0.105579   0.032701     0.030170\n",
       "6           ultra_big_brain_k50  0.010104  0.093079   0.033434     0.032799\n",
       "7          ultra_big_brain_k640  0.027681  0.084502   0.046516     0.045551\n",
       "8   ultra_duper_big_brain_naive  0.010675  0.079290   0.030365     0.022841\n",
       "9     ultra_duper_big_brain_ffd  0.011083  0.067300   0.030355     0.022893\n",
       "10   ultra_duper_big_brain_obfd  0.020519  0.075266   0.030239     0.022873"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ca05cd",
   "metadata": {},
   "source": [
    "Хуже всего работают ultra duper big brain потому что мы там подаем по одному элементу на батч (это вроде как должно пофикситься через flesh attention, но я так понял пока так надо реализовать) - сами по себе они такие же но там больше батчей получается (где-то в 2.5 раза а не в 16 - значит мы довольно хорошо пакуем)\n",
    "\n",
    "Из оставшихся хуже всех работает brain тк там всегда максимальный размер, дальше big brain там тоже есть такая проблема но не так часто (ровно как и ultra big brain k = 640) все остальные ultra big brain примерно одинаково работают\n",
    "\n",
    "Также видно что препроцессинг в obfd действительно сильно быстрее чем в ffd, тк асимптотика лучше"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac2fdd7",
   "metadata": {},
   "source": [
    "Имплементация:\n",
    "brain - падим втупую каждый семпл\n",
    "\n",
    "big brain - там просто колатор который смотрит на максимум\n",
    "\n",
    "ultra big brain - бьем на бины, дальше пушим в свой бин и в конце шафлим, далее передаем в семплер для каждого бина сколько батчей ему надо и шафлим индексы бина далее вытаскиваем их и получаем бин и из него уже индексы\n",
    "\n",
    "ultra duper big brain naive - пушим семпл в конец последнего примера если не влезает то создаем еще один и туда засовываем вторую часть, еще надо сделать маску это блочная матрица где в диагональном блоке делаем обычную казуальную маску\n",
    "\n",
    "ffd - тут за квадрат проходим в целом все как в описании задания\n",
    "\n",
    "obfd:\n",
    "\n",
    "делаем хешмапу которая из размера выдает все семплы в которых осталось ровно столько места\n",
    "\n",
    "также делаем ДО на то сколько семплов есть с конкретным количеством места, так мы можем за лог отвечать на запрос какое минимальное место есть что хотябы заданое количество\n",
    "\n",
    "далее идем по размерам от самого большого делаем запрос в ДО - он выдает лучший размер идем в хешмапу берем крайний индекс в листе чтобы легко удалить засовываем туда, обновляем то в какой лист в хешмапе он идет и обновляем два значения в ДО\n",
    "\n",
    "если же нет подходящих мест создаем новый семпл кладем туда понимаем где в хешмапе он лежит и обновляем ДО\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38abba8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
